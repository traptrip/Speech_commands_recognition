{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b38ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902cad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data\")\n",
    "CLASSES = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "WEIGHTS_PATH = \"TalTechNLP/voxlingua107-epaca-tdnn\" # \"speechbrain/google_speech_command_xvector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fc18344",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = EncoderClassifier.from_hparams(\n",
    "    source=WEIGHTS_PATH, \n",
    "    savedir=\"pretrained_models/voxlingua107-epaca-tdnn\",\n",
    "    run_opts={\"device\":\"cuda\"},\n",
    ")\n",
    "audio_normalizer = classifier.audio_normalizer\n",
    "label_encoder = classifier.hparams.label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d1e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sa']\n"
     ]
    }
   ],
   "source": [
    "out_prob, score, index, text_lab = classifier.classify_file(str(DATA_PATH / \"test\" / '0a0b032a8850131875bf.wav'))\n",
    "print(text_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113d0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_audio(path):\n",
    "#     signal, sr = torchaudio.load(str(path), channels_first=False)\n",
    "#     return audio_normalizer(signal, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3967570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18f0f6b49f6415487c90cd90151a0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# audio_filepaths = sorted(list((DATA_PATH / \"test\").glob(\"*.wav\")))\n",
    "\n",
    "# wavs = [\n",
    "#     load_audio(audiofile).unsqueeze(0)\n",
    "#     for audiofile in tqdm(audio_filepaths)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51cb4d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7d2026197249d8934f22675e7ca354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pred = []\n",
    "# embeddings = []\n",
    "# for wav in tqdm(wavs):\n",
    "#     rel_length = torch.tensor([1.0])\n",
    "#     embedding = classifier.encode_batch(wav, rel_length)\n",
    "#     out_prob = classifier.mods.classifier(embedding).squeeze(1)\n",
    "#     score, index = torch.max(out_prob, dim=-1)\n",
    "#     text_lab = label_encoder.decode_torch(index)\n",
    "#     pred.append(text_lab[0])\n",
    "#     embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd87ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0ca9cc2fed42b3901b7f99e06345fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = []\n",
    "audio_filepaths = sorted(list((DATA_PATH / \"test\").glob(\"*.wav\")))\n",
    "for audiofile in tqdm(audio_filepaths):\n",
    "    out_prob, score, index, text_lab = classifier.classify_file(str(audiofile))\n",
    "    pred.append(text_lab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ba2d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes        2904\n",
       "down       2892\n",
       "no         2868\n",
       "right      2834\n",
       "off        2796\n",
       "up         2779\n",
       "stop       2774\n",
       "left       2761\n",
       "on         2696\n",
       "go         2670\n",
       "silence    1351\n",
       "unknown     295\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d9fca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    \"id\": [a.stem for a in audio_filepaths],\n",
    "    \"category\": pred,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f09f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm *.wav"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
